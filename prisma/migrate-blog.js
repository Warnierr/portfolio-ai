/**
 * Script de migration des articles existants de /blog vers la base de donnÃ©es
 * ExÃ©cuter avec : node prisma/migrate-blog.js
 */

const { PrismaClient } = require("@prisma/client");
const prisma = new PrismaClient();

const articlesToMigrate = [
  {
    title: "5 erreurs courantes avec Apache Spark en production",
    slug: "5-erreurs-spark-production",
    excerpt:
      "Les piÃ¨ges classiques qui font crasher vos jobs Spark et comment les Ã©viter. Retour d'expÃ©rience sur des pipelines traitant des TBs de donnÃ©es.",
    content: `# 5 erreurs courantes avec Apache Spark en production

AprÃ¨s 7 ans Ã  dÃ©velopper et maintenir des pipelines Spark en production (BNP Paribas, Orange, ACC Industrie 4.0), j'ai identifiÃ© 5 erreurs qui reviennent systÃ©matiquement et qui peuvent faire crasher vos jobs ou exploser vos coÃ»ts.

## 1. Mauvais partitioning des donnÃ©es

### Le problÃ¨me
Un partitioning inadaptÃ© crÃ©e des **skewed partitions** : certaines partitions contiennent 100x plus de donnÃ©es que d'autres. RÃ©sultat : un seul executor travaille pendant que les autres attendent.

### SymptÃ´mes
- Job qui stagne Ã  99% pendant des heures
- OOM (Out of Memory) sur certains executors
- Temps d'exÃ©cution imprÃ©visible

### Solution
\`\`\`scala
// âŒ Mauvais : partitioning par dÃ©faut
df.groupBy("user_id").agg(...)

// âœ… Bon : repartition avant aggregation
df.repartition(200, col("user_id"))
  .groupBy("user_id")
  .agg(...)
\`\`\`

**RÃ¨gle empirique** : 1 partition = 128 MB de donnÃ©es. Pour 100 GB â†’ ~800 partitions.

## Points clÃ©s

- Toujours profiler vos jobs Spark avec Spark UI
- Ã‰vitez les shuffles inutiles
- Monitorer la mÃ©moire des executors
- Tester en staging avant prod`,
    category: "data-engineering",
    tags: JSON.stringify(["spark", "scala", "pyspark", "optimisation", "production"]),
    author: "Raouf Warnier",
    authorType: "human",
    readingTime: 8,
    status: "published",
    featured: true,
    publishedAt: new Date("2026-01-05"),
  },
  {
    title: "Airflow : patterns anti-fragiles pour pipelines robustes",
    slug: "airflow-patterns-anti-fragiles",
    excerpt:
      "Comment concevoir des DAGs Airflow qui survivent aux pannes rÃ©seau, timeouts API et erreurs silencieuses. Patterns testÃ©s en production.",
    content: `# Airflow : patterns anti-fragiles pour pipelines robustes

Airflow est devenu le standard pour orchestrer des pipelines data. Mais entre un DAG qui "marche" en dÃ©mo et un qui tourne 24/7 en prod sans intervention humaine, il y a un monde.

## Pattern 1 : Idempotence obligatoire

Chaque tÃ¢che doit Ãªtre **idempotente** : l'exÃ©cuter 10 fois = l'exÃ©cuter 1 fois.

\`\`\`python
# âŒ Mauvais
def append_to_table():
    df = extract_data()
    df.to_sql("table", engine, if_exists="append")

# âœ… Bon : upsert + clÃ© de dÃ©duplication
def upsert_to_table():
    df = extract_data()
    df = df.drop_duplicates(subset=["id", "date"])
    # Utiliser MERGE ou DELETE + INSERT
\`\`\`

## Pattern 2 : Retry avec backoff exponentiel

\`\`\`python
task = PythonOperator(
    task_id="extract_api",
    python_callable=extract,
    retries=5,
    retry_delay=timedelta(minutes=2),
    retry_exponential_backoff=True,
)
\`\`\`

## Points clÃ©s

- Toujours prÃ©voir des retries
- Logger abondamment
- Monitorer avec Prometheus + Grafana
- Tester les failure scenarios`,
    category: "dataops",
    tags: JSON.stringify(["airflow", "python", "orchestration", "patterns", "production"]),
    author: "Raouf Warnier",
    authorType: "human",
    readingTime: 7,
    status: "published",
    featured: false,
    publishedAt: new Date("2026-01-04"),
  },
];

async function main() {
  console.log("ðŸš€ DÃ©but de la migration des articles...\n");

  for (const articleData of articlesToMigrate) {
    try {
      // VÃ©rifier si l'article existe dÃ©jÃ 
      const existing = await prisma.article.findUnique({
        where: { slug: articleData.slug },
      });

      if (existing) {
        console.log(`âš ï¸  Article "${articleData.title}" existe dÃ©jÃ  (slug: ${articleData.slug})`);
        continue;
      }

      // CrÃ©er l'article
      const article = await prisma.article.create({
        data: articleData,
      });

      console.log(`âœ… Article migrÃ© : "${article.title}" (ID: ${article.id})`);
    } catch (error) {
      console.error(`âŒ Erreur lors de la migration de "${articleData.title}":`, error);
    }
  }

  console.log("\nâœ¨ Migration terminÃ©e !");
}

main()
  .then(async () => {
    await prisma.$disconnect();
  })
  .catch(async (e) => {
    console.error(e);
    await prisma.$disconnect();
    process.exit(1);
  });
