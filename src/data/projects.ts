/**
 * Exp√©riences professionnelles ‚Äî Raouf Warnier
 * Data Engineer & DevOps | Freelance
 */

export type CaseStudy = {
  slug: string;
  title: string;
  type: "mission" | "produit" | "experimentation";
  tldr: string;
  context: {
    client: string;
    duration: string;
    role: string;
    year: number;
  };
  problem: {
    situation: string;
    stakes: string;
  };
  constraints: string[];
  decisions: {
    choice: string;
    why: string;
    tradeoff?: string;
  }[];
  delivered: string[];
  results: {
    metrics?: string[];
    qualitative: string;
  };
  retrospective: string[];
  stack: string[];
  links?: { label: string; href: string }[];
  roadmap?: string[];
  media?: {
    type: "image" | "video";
    url: string;
    caption?: string;
  }[];
  status?: "en_cours" | "prototype" | "archive";
};

export const caseStudies: CaseStudy[] = [
  {
    slug: "budget-ai",
    title: "Budget AI ‚Äî Assistant Financier Intelligent",
    type: "produit",
    tldr: "Assistant personnel intelligent qui transforme des lignes de d√©penses brutes en conseils strat√©giques. Pr√©dictions de solde, d√©tection d'abonnements et coaching IA en temps r√©el.",
    context: {
      client: "Projet Personnel (SaaS)",
      duration: "En d√©veloppement continu",
      role: "Lead Fullstack & AI Engineer",
      year: 2024,
    },
    problem: {
      situation: "Les applications bancaires classiques regardent le pass√©. Les utilisateurs manquent de visibilit√© sur leur futur financier et de conseils personnalis√©s.",
      stakes: "Transformer la gestion financi√®re passive en un coaching proactif, intelligent, s√©curis√© et agr√©able √† utiliser via une interface conversationnelle.",
    },
    constraints: [
      "Confidentialit√© des donn√©es bancaires (Privacy by Design)",
      "Exp√©rience utilisateur fluide avec r√©ponses IA en streaming",
      "Architecture Serverless optimis√©e pour les co√ªts",
    ],
    decisions: [
      {
        choice: "Next.js 14 + Server-Sent Events (SSE)",
        why: "Pour un effet 'machine √† √©crire' fluide et natif sans bloquer l'interface utilisateur.",
      },
      {
        choice: "Middleware d'anonymisation (Privacy Layer)",
        why: "Couche logicielle qui anonymise toutes les donn√©es financi√®res (suppression des noms, comptes, lieux) AVANT l'envoi aux LLMs publics (OpenRouter).",
      },
      {
        choice: "Variables CSS S√©mantiques & Tailwind",
        why: "Syst√®me de th√®mes dynamiques (Neon, Ocean...) inject√©s par Context React pour changer l'ambiance sans recharger la page.",
      },
      {
        choice: "OpenRouter API",
        why: "Permet de switcher de mod√®le d'IA √† la vol√©e (Claude 3.5 Sonnet, GPT-4o) selon le besoin en intelligence.",
      },
    ],
    delivered: [
      "Assistant Financier Contextuel (Chat en temps r√©el avec vos donn√©es)",
      "Projection de Solde & 'Reste √† Vivre'",
      "D√©tection et isolement automatique des abonnements",
      "Interface Glassmorphism & Th√®mes dynamiques",
    ],
    results: {
      metrics: [
        "Temps de r√©ponse de l'IA < 200ms (SFE)",
        "Plus de 3 mod√®les LLM support√©s",
      ],
      qualitative: "Une application qui impressionne par son design 'Wow' (Glassmorphism, Recharts) et rassure par sa gestion stricte de la privacy.",
    },
    retrospective: [
      "La gestion des ReadableStreams entre serveur et client (SSE) a demand√© une configuration fine sur Next.js.",
      "L'architecture 'Privacy-First' est le v√©ritable atout confiance du produit.",
    ],
    stack: [
      "Next.js 14",
      "TypeScript",
      "Tailwind CSS",
      "Shadcn/UI",
      "Framer Motion",
      "Recharts",
      "Prisma",
      "PostgreSQL (Neon)",
      "NextAuth.js",
      "OpenRouter API"
    ],
    roadmap: [
      "Connexion Bancaire Directe (via GoCardless/Plaid) pour ne plus importer de CSV.",
      "Mode Multi-Worskapce (Budget Perso / Budget Pro).",
      "Application Mobile (via React Native ou PWA)."
    ],
    links: [
      { label: "üî¥ Live Demo : Budget AI", href: "https://budget.kenshu.dev" },
      { label: "üì± Page de l'app", href: "/app/budget-ai" }
    ],
  },
  {
    slug: "ai-compliance-audit-tool",
    title: "AI Compliance Audit Tool ‚Äî Conformit√© AI Act & RGPD",
    type: "experimentation",
    tldr: "Outil d'audit automatis√© pour √©valuer la conformit√© des syst√®mes d'IA selon le cadre europ√©en AI Act et RGPD. Classification des risques, checklists r√©glementaires et rapports d√©taill√©s.",
    context: {
      client: "Projet R&D Personnel",
      duration: "En d√©veloppement (2025-2026)",
      role: "Lead Engineer & Compliance Researcher",
      year: 2025,
    },
    problem: {
      situation: "Les entreprises europ√©ennes devront auditer leurs syst√®mes d'IA d'ici 2026-2027 selon l'AI Act. Pas d'outils techniques accessibles pour les √©quipes produit.",
      stakes: "Cr√©er un outil qui traduit les obligations l√©gales en checklists techniques exploitables par les d√©veloppeurs et product managers.",
    },
    constraints: [
      "Interpr√©tation correcte du cadre r√©glementaire AI Act",
      "Interface simple pour non-juristes",
      "√âvolutivit√© (le texte √©voluera)",
    ],
    decisions: [
      {
        choice: "Architecture modulaire par cat√©gorie de risque",
        why: "Le texte AI Act est structur√© par niveaux de risque (inacceptable, √©lev√©, limit√©, minimal). L'outil refl√®te cette logique.",
      },
      {
        choice: "Checklist interactive avec export PDF/JSON",
        why: "Les √©quipes ont besoin de rapports partageables avec direction et juristes.",
      },
      {
        choice: "Base de connaissances int√©gr√©e (articles de loi)",
        why: "Chaque question renvoie √† l'article pr√©cis du r√®glement pour tra√ßabilit√©.",
      },
    ],
    delivered: [
      "Interface de classification des syst√®mes IA",
      "Checklist dynamique selon le niveau de risque d√©tect√©",
      "Rapport d'audit exportable (PDF)",
      "Base de connaissances AI Act int√©gr√©e",
    ],
    results: {
      metrics: [
        "Prototype fonctionnel v0.1",
        "Couverture de 80% des obligations high-risk",
      ],
      qualitative: "Un outil early pour anticiper les besoins 2026-2027. Positionnement unique entre tech et r√©glementation.",
    },
    retrospective: [
      "La complexit√© du texte AI Act n√©cessite une veille constante.",
      "L'outil est un excellent diff√©renciateur pour attirer des missions compliance.",
    ],
    stack: ["Next.js 15", "TypeScript", "Tailwind", "Prisma", "PostgreSQL", "PDF Generation"],
    roadmap: [
      "Int√©gration API pour audit automatis√© de code/mod√®les",
      "Module RGPD compl√©mentaire",
      "Multi-langue (EN/FR)",
    ],
    links: [{ label: "üì± Page de l'app", href: "/app/ai-compliance" }],
    status: "prototype",
  },
  {
    slug: "data-engineer-bnpp",
    title: "Ing√©nieur Data / Big Data ‚Äî BNP Paribas",
    type: "mission",
    tldr: "Migration d'ETL legacy vers architecture moderne. Debugging de pipelines complexes, automatisation Jenkins et d√©veloppement Scala/Spark SQL.",
    context: {
      client: "BNP Paribas",
      duration: "Sept 2025 - D√©c 2025",
      role: "Ing√©nieur Data",
      year: 2025,
    },
    problem: {
      situation: "Maintenance et √©volution d'un SI critique bancaire. N√©cessit√© de comprendre et migrer des pipelines legacy sans documentation.",
      stakes: "Assurer la continuit√© de service des flux financiers tout en migrant vers une stack plus performante et maintenable.",
    },
    constraints: [
      "Environnement bancaire hautement s√©curis√©",
      "Syst√®mes existants complexes (Reverse Engineering)",
      "Qualit√© de service critique (SLA strict)",
    ],
    decisions: [
      {
        choice: "Scala & Spark SQL",
        why: "Performance et typage fort pour les traitements critiques √† grande √©chelle.",
      },
      {
        choice: "Jenkins pour l'orchestration",
        why: "Automatisation compl√®te des flux pour r√©duire les interventions manuelles et s√©curiser les d√©ploiements.",
      },
    ],
    delivered: [
      "Migration de pipelines ETL legacy vers nouvelle architecture",
      "Scripts de debugging et d'analyse de donn√©es",
      "Documentation technique d√©taill√©e des flux migr√©s",
    ],
    results: {
      metrics: [
        "100% des flux migr√©s sans r√©gression",
        "R√©duction du temps de debug",
      ],
      qualitative: "Une transition fluide vers une architecture plus moderne, avec une meilleure visibilit√© sur les traitements.",
    },
    retrospective: [
      "L'analyse approfondie (reverse engineering) avant le code est la cl√© du succ√®s sur du legacy.",
    ],
    stack: ["Scala", "Spark", "Spark SQL", "Jenkins", "Shell", "Linux", "Hadoop", "Git"],
  },
  {
    slug: "devops-orange-bigdata",
    title: "Infrastructure Big Data ‚Äî Orange",
    type: "mission",
    tldr: "Automatisation du d√©ploiement des outils Big Data (Zeppelin, Airflow, Spark, Grafana) avec Ansible. Migration de donn√©es critiques MariaDB vers MSSQL.",
    context: {
      client: "Orange via Inetum",
      duration: "Depuis ao√ªt 2024",
      role: "Ing√©nieur DevOps",
      year: 2024,
    },
    problem: {
      situation: "D√©ploiement manuel des outils Big Data chronophage et source d'erreurs. Migration de base de donn√©es legacy n√©cessaire.",
      stakes: "Assurer la fiabilit√© des environnements de production et garantir l'int√©grit√© des donn√©es lors de la migration.",
    },
    constraints: [
      "Environnements Linux √† haute disponibilit√©",
      "√âquipes multidisciplinaires √† coordonner",
    ],
    decisions: [
      {
        choice: "Ansible pour l'automatisation",
        why: "Idempotence garantie et playbooks r√©utilisables pour Zeppelin, Airflow, Spark.",
      },
      {
        choice: "Scripts Shell pour l'op√©rationnel",
        why: "Surveillance et d√©pannage rapide des services Big Data en production.",
      },
    ],
    delivered: [
      "Playbooks Ansible pour d√©ploiement automatis√©",
      "Scripts de migration MariaDB ‚Üí MSSQL avec validation",
      "Monitoring Prometheus/Grafana",
    ],
    results: {
      metrics: [
        "Temps de d√©ploiement r√©duit de 80%",
        "Z√©ro perte de donn√©es lors des migrations",
      ],
      qualitative: "Les √©quipes peuvent d√©sormais d√©ployer des environnements Big Data complets en quelques minutes.",
    },
    retrospective: [
      "L'automatisation Ansible a √©t√© un game-changer pour la reproductibilit√© des environnements.",
    ],
    stack: ["Ansible", "Zeppelin", "Airflow", "Spark", "Grafana", "Prometheus", "Linux", "MariaDB", "MSSQL"],
  },
  {
    slug: "iot-thingworx-safran",
    title: "Plateforme IoT & Monitoring ‚Äî Safran",
    type: "mission",
    tldr: "D√©veloppement de solutions data IoT avec ThingWorx, migration PostgreSQL vers MSSQL, et mise en place de pipelines CI/CD GitLab.",
    context: {
      client: "Safran via Inetum",
      duration: "Juin 2023 - Ao√ªt 2024",
      role: "Consultant IoT et Base de Donn√©es",
      year: 2024,
    },
    problem: {
      situation: "Syst√®mes IoT industriels n√©cessitant une surveillance temps r√©el et des donn√©es fiables pour la prise de d√©cision.",
      stakes: "Assurer la qualit√© des produits a√©ronautiques via un monitoring pr√©cis des m√©triques de production.",
    },
    constraints: [
      "Environnement industriel critique (a√©ronautique)",
      "Collaboration internationale (workshops en anglais)",
    ],
    decisions: [
      {
        choice: "ThingWorx pour l'IoT",
        why: "Plateforme industrielle √©prouv√©e avec capacit√©s de visualisation temps r√©el.",
      },
      {
        choice: "Migration PostgreSQL ‚Üí MSSQL",
        why: "Standardisation des bases de donn√©es du groupe tout en assurant la continuit√© des donn√©es.",
      },
    ],
    delivered: [
      "Syst√®me de surveillance temps r√©el des services IoT",
      "Dashboard de m√©triques et alerting",
      "Pipelines CI/CD GitLab avec PowerShell",
      "Tests automatis√©s Jest",
    ],
    results: {
      metrics: [
        "Migration de volumes massifs sans interruption",
        "Couverture de tests √† 85%",
      ],
      qualitative: "Une infrastructure data robuste supportant les d√©cisions qualit√© en production a√©ronautique.",
    },
    retrospective: [
      "La documentation technique d√©taill√©e a √©t√© cruciale pour le transfert de comp√©tences.",
    ],
    stack: ["ThingWorx", "JavaScript", "SQL", "PostgreSQL", "MSSQL", "GitLab CI", "PowerShell", "Jest"],
  },
  {
    slug: "data-engineer-acc-industrie",
    title: "Pipelines Big Data ‚Äî ACC Industrie 4.0",
    type: "mission",
    tldr: "D√©veloppement de pipelines ETL avec Spark et Hadoop pour traiter de gros volumes de donn√©es industrielles. Orchestration Airflow et stockage MinIO.",
    context: {
      client: "ACC via Inetum",
      duration: "Sept 2022 - Juin 2023",
      role: "Data Engineer",
      year: 2023,
    },
    problem: {
      situation: "Volumes massifs de donn√©es de production n√©cessitant un traitement automatis√© et une ingestion fiable.",
      stakes: "Permettre l'analyse des donn√©es industrielles pour optimiser les processus de fabrication.",
    },
    constraints: [
      "Gestion de gros volumes (TBs)",
      "Conformit√© aux normes de gestion des donn√©es",
    ],
    decisions: [
      {
        choice: "Spark et Hadoop pour le traitement",
        why: "Technologies √©prouv√©es pour le Big Data avec scalabilit√© horizontale.",
      },
      {
        choice: "Airflow pour l'orchestration",
        why: "DAGs flexibles et monitoring int√©gr√© des pipelines.",
      },
    ],
    delivered: [
      "Pipelines d'ingestion MinIO ‚Üí SQL via Airflow",
      "Optimisation des performances de traitement",
      "Documentation et collaboration avec l'√©quipe Data Architecture",
    ],
    results: {
      metrics: [
        "R√©duction des co√ªts de traitement de 40%",
        "Temps de traitement divis√© par 3",
      ],
      qualitative: "Une infrastructure data moderne permettant des analyses industrielles √† grande √©chelle.",
    },
    retrospective: [
      "La collaboration avec l'√©quipe Data Architecture a √©t√© essentielle pour les bonnes pratiques.",
    ],
    stack: ["Spark", "Hadoop", "Airflow", "MinIO", "Python", "SQL", "PostgreSQL"],
  },

];

// Compatibilit√© avec l'ancien format
export const projects = caseStudies.map((cs) => ({
  name: cs.title,
  slug: cs.slug,
  problem: cs.problem.situation,
  solution: cs.tldr,
  architecture: cs.decisions.map((d) => d.choice).join(", "),
  stack: cs.stack,
  proof: cs.results.qualitative,
  impact: cs.results.metrics?.join(" ‚Ä¢ ") ?? cs.results.qualitative,
  lessons: cs.retrospective,
  decisions: cs.decisions.map((d) => d.choice),
  risks: cs.constraints,
  exploreNext: [],
  links: cs.links,
}));
